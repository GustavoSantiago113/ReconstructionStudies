{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba409c8c",
   "metadata": {},
   "source": [
    "# Dust3r implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e9b970",
   "metadata": {},
   "source": [
    "## Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d291181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning, cannot find cuda-compiled version of RoPE2D, using a slow pytorch version instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gnoceras\\Documents\\GustavoPersonal\\ReconstructionStudies\\notebooks\\../dust3r\\dust3r\\cloud_opt\\base_opt.py:275: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @torch.cuda.amp.autocast(enabled=False)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../dust3r/\")\n",
    "\n",
    "from dust3r.inference import inference\n",
    "from dust3r.model import AsymmetricCroCo3DStereo\n",
    "from dust3r.utils.image import load_images\n",
    "from dust3r.image_pairs import make_pairs\n",
    "from dust3r.cloud_opt import global_aligner, GlobalAlignerMode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca903cd",
   "metadata": {},
   "source": [
    "## Setting environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2afdb0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Loading a list of 3 images\n",
      " - adding ../segmented_images/stop_01_20251128_141444.jpg with resolution 3000x4000 --> 384x512\n",
      " - adding ../segmented_images/stop_10_20251128_141602.jpg with resolution 3000x4000 --> 384x512\n",
      " - adding ../segmented_images/stop_20_20251128_141730.jpg with resolution 3000x4000 --> 384x512\n",
      " (Found 3 images)\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(\"../\")\n",
    "from utils.imageSelector import select_equally_distributed_images\n",
    "\n",
    "device = 'cuda'  # or 'cuda' if you have a GPU\n",
    "batch_size = 1\n",
    "schedule = 'cosine'\n",
    "lr = 0.01 # learning rate for global alignment optimization\n",
    "niter = 300 # number of iterations for global alignment optimization\n",
    "\n",
    "model_name = \"naver/DUSt3R_ViTLarge_BaseDecoder_512_dpt\"\n",
    "\n",
    "# you can put the path to a local checkpoint in model_name if needed\n",
    "model = AsymmetricCroCo3DStereo.from_pretrained(model_name).to(device)\n",
    "\n",
    "loaded_images = select_equally_distributed_images(\"../segmented_images/\", 3)\n",
    "# load_images can take a list of images or a directory\n",
    "images = load_images(loaded_images, size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d908c2",
   "metadata": {},
   "source": [
    "## Infering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38d7f402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Inference with model on 6 image pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]c:\\Users\\gnoceras\\Documents\\GustavoPersonal\\ReconstructionStudies\\notebooks\\../dust3r\\dust3r\\inference.py:44: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=bool(use_amp)):\n",
      "c:\\Users\\gnoceras\\Documents\\GustavoPersonal\\ReconstructionStudies\\notebooks\\../dust3r\\dust3r\\model.py:206: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "c:\\Users\\gnoceras\\Documents\\GustavoPersonal\\ReconstructionStudies\\notebooks\\../dust3r\\dust3r\\inference.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.31it/s]\n"
     ]
    }
   ],
   "source": [
    "pairs = make_pairs(images, scene_graph='complete', prefilter=None, symmetrize=True)\n",
    "output = inference(pairs, model, device, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc009f3f",
   "metadata": {},
   "source": [
    "## Global Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20e3c53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " init edge (0*,2*) score=4.184772968292236\n",
      " init edge (1*,0) score=2.235483407974243\n",
      " init loss = 0.004356085788458586\n",
      "Global alignement - optimizing for:\n",
      "['pw_poses', 'im_depthmaps', 'im_poses', 'im_focals']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]c:\\Users\\gnoceras\\Documents\\GustavoPersonal\\ReconstructionStudies\\notebooks\\../dust3r\\dust3r\\cloud_opt\\base_opt.py:366: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
      "Consider using tensor.detach() first. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\autograd\\generated\\python_variable_methods.cpp:837.)\n",
      "  return float(loss), lr\n",
      "100%|██████████| 300/300 [00:08<00:00, 36.74it/s, lr=1.27413e-06 loss=0.00225511]\n"
     ]
    }
   ],
   "source": [
    "# next we'll use the global_aligner to align the predictions\n",
    "# depending on your task, you may be fine with the raw output and not need it\n",
    "# with only two input images, you could use GlobalAlignerMode.PairViewer: it would just convert the output\n",
    "# if using GlobalAlignerMode.PairViewer, no need to run compute_global_alignment\n",
    "scene = global_aligner(output, device=device, mode=GlobalAlignerMode.PointCloudOptimizer)\n",
    "loss = scene.compute_global_alignment(init=\"mst\", niter=niter, schedule=schedule, lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e29ee5",
   "metadata": {},
   "source": [
    "## Showing the reconstructed scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c45850f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dust3r.viz.SceneViz at 0x1e99abc2490>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieve useful values from scene:\n",
    "imgs = scene.imgs\n",
    "focals = scene.get_focals()\n",
    "poses = scene.get_im_poses()\n",
    "pts3d = scene.get_pts3d()\n",
    "confidence_masks = scene.get_masks()\n",
    "\n",
    "# visualize reconstruction\n",
    "scene.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459f20d4",
   "metadata": {},
   "source": [
    "## Saving to PLY file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15cf3974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "Saved 103279 points to '../reconstructions/dust3r_3_True.ply'\n"
     ]
    }
   ],
   "source": [
    "# Save pts3d (tensor/ndarray/list) to a PLY file with optional masks/colors\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "\n",
    "def _to_numpy(x):\n",
    "    try:\n",
    "        import torch\n",
    "        if isinstance(x, torch.Tensor):\n",
    "            return x.detach().cpu().numpy()\n",
    "    except Exception:\n",
    "        pass\n",
    "    return np.asarray(x)\n",
    "\n",
    "def save_pts3d_ply(pts3d, masks=None, colors=None, filename=\"output_pointcloud.ply\"):\n",
    "    \"\"\"\n",
    "    Save 3D points to a PLY file.\n",
    "    - pts3d can be:\n",
    "        * a single array/tensor of shape (H,W,3) or (N,3)\n",
    "        * a list/tuple of arrays/tensors [(H,W,3), ...] or [(M,3), ...]\n",
    "    - masks (optional) can match pts3d structure: single (H,W) bool array or list of masks\n",
    "    - colors (optional) can be same shape as pts3d (H,W,3) or list; values 0-255 or 0-1 accepted\n",
    "    \"\"\"\n",
    "    is_sequence = isinstance(pts3d, (list, tuple))\n",
    "    pts_list = pts3d if is_sequence else [pts3d]\n",
    "    masks_list = None if masks is None else (masks if isinstance(masks, (list, tuple)) else [masks])\n",
    "    colors_list = None if colors is None else (colors if isinstance(colors, (list, tuple)) else [colors])\n",
    "\n",
    "    collected_pts = []\n",
    "    collected_cols = []\n",
    "\n",
    "    for i, p in enumerate(pts_list):\n",
    "        p_np = _to_numpy(p)\n",
    "        if p_np.size == 0:\n",
    "            continue\n",
    "\n",
    "        if p_np.ndim == 3 and p_np.shape[2] == 3:\n",
    "            if masks_list is not None and i < len(masks_list):\n",
    "                m = _to_numpy(masks_list[i]).astype(bool)\n",
    "            else:\n",
    "                m = np.isfinite(p_np[..., 0])\n",
    "            pts_sel = p_np[m]\n",
    "        elif p_np.ndim == 2 and p_np.shape[1] == 3:\n",
    "            pts_sel = p_np.reshape(-1, 3)\n",
    "            if masks_list is not None and i < len(masks_list):\n",
    "                m = _to_numpy(masks_list[i]).reshape(-1).astype(bool)\n",
    "                pts_sel = pts_sel[m]\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported pts3d shape {p_np.shape}\")\n",
    "\n",
    "        collected_pts.append(pts_sel.reshape(-1, 3))\n",
    "\n",
    "        if colors_list is not None and i < len(colors_list):\n",
    "            c_np = _to_numpy(colors_list[i])\n",
    "            if c_np.ndim == 3 and c_np.shape[2] == 3:\n",
    "                c_sel = c_np[m].reshape(-1, 3)\n",
    "            elif c_np.ndim == 2 and c_np.shape[1] == 3:\n",
    "                c_sel = c_np.reshape(-1, 3)\n",
    "                if masks_list is not None and i < len(masks_list):\n",
    "                    c_sel = c_sel[m]\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported colors shape {c_np.shape}\")\n",
    "            collected_cols.append(c_sel.reshape(-1, 3))\n",
    "\n",
    "    if not collected_pts:\n",
    "        raise RuntimeError(\"No points to save.\")\n",
    "\n",
    "    pts_all = np.concatenate(collected_pts, axis=0)\n",
    "\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(pts_all.astype(np.float64))\n",
    "\n",
    "    if collected_cols:\n",
    "        cols_all = np.concatenate(collected_cols, axis=0).astype(np.float64)\n",
    "        if cols_all.max() > 1.5:\n",
    "            cols_all = cols_all / 255.0\n",
    "        cols_all = np.clip(cols_all, 0.0, 1.0)\n",
    "        pcd.colors = o3d.utility.Vector3dVector(cols_all)\n",
    "\n",
    "    ok = o3d.io.write_point_cloud(filename, pcd)\n",
    "    if not ok:\n",
    "        raise RuntimeError(f\"Failed to write point cloud to {filename}\")\n",
    "    print(f\"Saved {len(pts_all)} points to '{filename}'\")\n",
    "\n",
    "# Example usage:\n",
    "save_pts3d_ply(pts3d, masks=confidence_masks, colors=imgs, filename=\"../reconstructions/dust3r_3_True.ply\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269d273f",
   "metadata": {},
   "source": [
    "## Visualizing the point cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21a60c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 103279 points from ../reconstructions/dust3r_3_True.ply\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import open3d as o3d\n",
    "\n",
    "from utils.pointCloud import visualize_point_cloud\n",
    "\n",
    "# Example: read the PLY we saved earlier, clean it, and visualize\n",
    "ply_path = '../reconstructions/dust3r_3_True.ply'\n",
    "try:\n",
    "    pcd = o3d.io.read_point_cloud(ply_path)\n",
    "except Exception:\n",
    "    pcd = None\n",
    "\n",
    "if pcd is None or len(pcd.points) == 0:\n",
    "    print(f'Could not read {ply_path} or file empty — you can call save_pts3d_ply first or pass another path.')\n",
    "else:\n",
    "    print(f'Loaded {len(pcd.points)} points from {ply_path}')\n",
    "    visualize_point_cloud(pcd, window_name='Dust3R Reconstruction (cleaned)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809178d5",
   "metadata": {},
   "source": [
    "## Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5107c159",
   "metadata": {},
   "source": [
    "| Number of Images | Using Segmentation? | Output number of points | Reconstruction Time in GPU | Point Cloud Reconstruction Quality (1-10) |\n",
    "| - | - | - | - | - |\n",
    "| 20 | No | 1,927,307 | 41.18 min |  3 |\n",
    "| 10 | No | 948,252 | 81 s | 3 |\n",
    "| 8 | No | 764,791 | 164s | 4 |\n",
    "| 4 | No | 362,816 | 15s | 3 |\n",
    "| 3 | No | 282,624 | 10s | 2 |\n",
    "| 20 | Yes | 852,987 | 47 min | 5 | \n",
    "| 10 | Yes | 420,200 | 81s | 5 |  \n",
    "| 8 | Yes | 337,370 | 52s | 5 | \n",
    "| 4 | Yes | 152,935 | 14s | 6 | \n",
    "| 3 | Yes | 103,279 | 10s |4 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba2d92d",
   "metadata": {},
   "source": [
    "Overall, the reconstructions are better with segmented images. All of them would need further cleaning to be presentable"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
