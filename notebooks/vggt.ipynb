{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bede0e01",
   "metadata": {},
   "source": [
    "# VGG-T Reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba0ea00",
   "metadata": {},
   "source": [
    "## Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0994b4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import sys\n",
    "import glob\n",
    "import gc\n",
    "import time\n",
    "\n",
    "sys.path.append(\"../vggt/\")\n",
    "\n",
    "from visual_util import predictions_to_glb\n",
    "from vggt.models.vggt import VGGT\n",
    "from vggt.utils.load_fn import load_and_preprocess_images\n",
    "from vggt.utils.pose_enc import pose_encoding_to_extri_intri\n",
    "from vggt.utils.geometry import unproject_depth_map_to_point_map\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from utils.imageSelector import select_equally_distributed_images\n",
    "\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13f382b",
   "metadata": {},
   "source": [
    "## Setting environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9af62135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing and loading VGGT model...\n"
     ]
    }
   ],
   "source": [
    "print(\"Initializing and loading VGGT model...\")\n",
    "\n",
    "model = VGGT()\n",
    "_URL = \"https://huggingface.co/facebook/VGGT-1B/resolve/main/model.pt\"\n",
    "model.load_state_dict(torch.hub.load_state_dict_from_url(_URL))\n",
    "\n",
    "model.eval()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86aa0ef4",
   "metadata": {},
   "source": [
    "## Getting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c075d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(target_dir, model, image_paths=None):\n",
    "    \"\"\"\n",
    "    Run the VGGT model on images in the 'target_dir/images' folder and return predictions.\n",
    "    If `image_paths` is provided, run on that list instead of scanning the directory.\n",
    "    \"\"\"\n",
    "    print(f\"Processing images from {target_dir}\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Device check\n",
    "    device = \"cpu\"\n",
    "    # Move model to device\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Load and preprocess images (either provided list or all in folder)\n",
    "    if image_paths is None:\n",
    "        image_names = glob.glob(os.path.join(target_dir, \"images\", \"*\"))\n",
    "        image_names = sorted(image_names)\n",
    "    else:\n",
    "        image_names = list(image_paths)\n",
    "    print(f\"Found {len(image_names)} images to process\")\n",
    "    if len(image_names) == 0:\n",
    "        raise ValueError(\"No images found. Check your upload or selection.\")\n",
    "\n",
    "    images = load_and_preprocess_images(image_names).to(device)\n",
    "    print(f\"Preprocessed images shape: {images.shape}\")\n",
    "\n",
    "    # Run inference\n",
    "    print(\"Running inference...\")\n",
    "    with torch.no_grad():\n",
    "        predictions = model(images)\n",
    "\n",
    "    # Convert pose encoding to extrinsic and intrinsic matrices\n",
    "    print(\"Converting pose encoding to extrinsic and intrinsic matrices...\")\n",
    "    extrinsic, intrinsic = pose_encoding_to_extri_intri(predictions[\"pose_enc\"], images.shape[-2:])\n",
    "    predictions[\"extrinsic\"] = extrinsic\n",
    "    predictions[\"intrinsic\"] = intrinsic\n",
    "\n",
    "    # Convert tensors to numpy\n",
    "    for key in list(predictions.keys()):\n",
    "        if isinstance(predictions[key], torch.Tensor):\n",
    "            predictions[key] = predictions[key].cpu().numpy().squeeze(0)  # remove batch dimension\n",
    "\n",
    "    # Generate world points from depth map\n",
    "    print(\"Computing world points from depth map...\")\n",
    "    depth_map = predictions[\"depth\"]  # (S, H, W, 1)\n",
    "    world_points = unproject_depth_map_to_point_map(depth_map, predictions[\"extrinsic\"], predictions[\"intrinsic\"])\n",
    "    predictions[\"world_points_from_depth\"] = world_points\n",
    "\n",
    "    # Clean up\n",
    "    torch.cuda.empty_cache()\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4fa94fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_reconstruction(target_dir,\n",
    "    image_dir,\n",
    "    conf_thres=50.0,\n",
    "    frame_filter=\"All\",\n",
    "    mask_black_bg=True,\n",
    "    mask_white_bg=False,\n",
    "    show_cam=True,\n",
    "    mask_sky=False,\n",
    "    prediction_mode=\"Pointmap Regression\",\n",
    "    n_select=10,\n",
    "    \n",
    "):\n",
    "    \"\"\"\n",
    "    Perform reconstruction using the already-created target_dir/images.\n",
    "\n",
    "    This version selects `n_select` equally-distributed images from\n",
    "    `target_dir/images` (via `select_equally_distributed_images`) and runs\n",
    "    the model on that subset. If the selector returns empty, falls back to\n",
    "    running on all images.\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(target_dir) or target_dir == \"None\":\n",
    "        return None, \"No valid target directory found. Please upload first.\", None, None\n",
    "\n",
    "    start_time = time.time()\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Select equally distributed images\n",
    "    \n",
    "    selected_images = select_equally_distributed_images(image_dir, n_select)\n",
    "    if selected_images:\n",
    "        print(f\"Selected {len(selected_images)} equally distributed images for reconstruction.\")\n",
    "    else:\n",
    "        # fallback: use all images in the folder\n",
    "        print(\"Selector returned no images, falling back to all images in the folder.\")\n",
    "        selected_images = sorted(glob.glob(os.path.join(image_dir, \"*\")))\n",
    "\n",
    "    # Prepare frame_filter choices from selected images\n",
    "    frame_filter_choices = [\"All\"] + [f\"{i}: {os.path.basename(p)}\" for i, p in enumerate(selected_images)]\n",
    "\n",
    "    print(\"Running run_model on chosen images...\")\n",
    "    with torch.no_grad():\n",
    "        predictions = run_model(target_dir, model, image_paths=selected_images)\n",
    "\n",
    "    # Save predictions\n",
    "    prediction_save_path = os.path.join(target_dir, \"predictions.npz\")\n",
    "    # ensure predictions keys are numpy arrays (they should be already from run_model)\n",
    "    np.savez(prediction_save_path, **predictions)\n",
    "\n",
    "    # Handle None frame_filter\n",
    "    if frame_filter is None:\n",
    "        frame_filter = \"All\"\n",
    "\n",
    "    # Build a GLB file name\n",
    "    glbfile = os.path.join(\n",
    "        target_dir,\n",
    "        f\"Reconstruction.glb\",\n",
    "    )\n",
    "\n",
    "    # Convert predictions to GLB\n",
    "    glbscene = predictions_to_glb(\n",
    "        predictions,\n",
    "        conf_thres=conf_thres,\n",
    "        filter_by_frames=frame_filter,\n",
    "        mask_black_bg=mask_black_bg,\n",
    "        mask_white_bg=mask_white_bg,\n",
    "        show_cam=show_cam,\n",
    "        mask_sky=mask_sky,\n",
    "        target_dir=target_dir,\n",
    "        prediction_mode=prediction_mode,\n",
    "    )\n",
    "    glbscene.export(file_obj=glbfile)\n",
    "\n",
    "    # Cleanup\n",
    "    del predictions\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Total time: {end_time - start_time:.2f} seconds (including IO)\")\n",
    "    print(f\"Reconstruction Success ({len(selected_images)} frames).\")\n",
    "\n",
    "    return glbfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19c058ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_visualization(\n",
    "    target_dir, conf_thres, frame_filter, mask_black_bg, mask_white_bg, show_cam, mask_sky, prediction_mode, is_example\n",
    "):\n",
    "    \"\"\"\n",
    "    Reload saved predictions from npz, create (or reuse) the GLB for new parameters,\n",
    "    and return it for the 3D viewer. If is_example == \"True\", skip.\n",
    "    \"\"\"\n",
    "\n",
    "    # If it's an example click, skip as requested\n",
    "    if is_example == \"True\":\n",
    "        return None, \"No reconstruction available. Please click the Reconstruct button first.\"\n",
    "\n",
    "    if not target_dir or target_dir == \"None\" or not os.path.isdir(target_dir):\n",
    "        return None, \"No reconstruction available. Please click the Reconstruct button first.\"\n",
    "\n",
    "    predictions_path = os.path.join(target_dir, \"predictions.npz\")\n",
    "    if not os.path.exists(predictions_path):\n",
    "        return None, f\"No reconstruction available at {predictions_path}. Please run 'Reconstruct' first.\"\n",
    "\n",
    "    key_list = [\n",
    "        \"pose_enc\",\n",
    "        \"depth\",\n",
    "        \"depth_conf\",\n",
    "        \"world_points\",\n",
    "        \"world_points_conf\",\n",
    "        \"images\",\n",
    "        \"extrinsic\",\n",
    "        \"intrinsic\",\n",
    "        \"world_points_from_depth\",\n",
    "    ]\n",
    "\n",
    "    loaded = np.load(predictions_path)\n",
    "    predictions = {key: np.array(loaded[key]) for key in key_list}\n",
    "\n",
    "    glbfile = os.path.join(\n",
    "        target_dir,\n",
    "        f\"Reconstruction.glb\",\n",
    "    )\n",
    "\n",
    "    glbscene = predictions_to_glb(\n",
    "        predictions,\n",
    "        conf_thres=conf_thres,\n",
    "        filter_by_frames=frame_filter,\n",
    "        mask_black_bg=mask_black_bg,\n",
    "        mask_white_bg=mask_white_bg,\n",
    "        show_cam=show_cam,\n",
    "        mask_sky=mask_sky,\n",
    "        target_dir=target_dir,\n",
    "        prediction_mode=prediction_mode,\n",
    "    )\n",
    "    glbscene.export(file_obj=glbfile)\n",
    "\n",
    "    return glbfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547a07f4",
   "metadata": {},
   "source": [
    "## Performing Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "388adea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 10 equally distributed images for reconstruction.\n",
      "Running run_model on chosen images...\n",
      "Processing images from ../\n",
      "Found 10 images to process\n",
      "Preprocessed images shape: torch.Size([10, 3, 392, 518])\n",
      "Running inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gnoceras\\Documents\\GustavoPersonal\\ReconstructionStudies\\notebooks\\../vggt\\vggt\\models\\vggt.py:65: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting pose encoding to extrinsic and intrinsic matrices...\n",
      "Computing world points from depth map...\n",
      "Building GLB scene\n",
      "Using Pointmap Branch\n",
      "GLB Scene built\n",
      "Total time: 91.99 seconds (including IO)\n",
      "Reconstruction Success (10 frames).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../Reconstruction.glb'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_dir = \"../\"\n",
    "image_dir = os.path.join(target_dir, \"Photos\")\n",
    "perform_reconstruction(target_dir=target_dir, image_dir=image_dir, n_select= 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35577858",
   "metadata": {},
   "source": [
    "## Showing the Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bedfeca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building GLB scene\n",
      "Using Pointmap Branch\n",
      "GLB Scene built\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../Reconstruction.glb'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_visualization(target_dir, 60, \"All\", True, False, False, False, \"Predicted Pointmap\", \"False\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c64731",
   "metadata": {},
   "source": [
    "## Getting Point Cloud as PLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a3af33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "Saved point cloud with 812104 points to: ../Reconstruction_PC.ply\n"
     ]
    }
   ],
   "source": [
    "import trimesh\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "\n",
    "# Load the GLB file\n",
    "scene = trimesh.load(os.path.join(target_dir, 'Reconstruction.glb'))\n",
    "# Some GLB exports may use a different geometry key; try to find the first geometry\n",
    "if hasattr(scene, 'geometry') and len(scene.geometry) > 0:\n",
    "    # pick the first geometry\n",
    "    point_cloud_trimesh = list(scene.geometry.values())[0]\n",
    "else:\n",
    "    # fallback if scene is a PointCloud directly\n",
    "    point_cloud_trimesh = scene\n",
    "\n",
    "points = point_cloud_trimesh.vertices\n",
    "colors = point_cloud_trimesh.colors if hasattr(point_cloud_trimesh, 'colors') else None\n",
    "\n",
    "# Create Open3D point cloud\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(points)\n",
    "if colors is not None:\n",
    "    try:\n",
    "        pcd.colors = o3d.utility.Vector3dVector(colors[:, :3] / 255.0)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# Save as .ply\n",
    "ply_path = os.path.join(target_dir, 'Reconstruction_PC.ply')\n",
    "ok = o3d.io.write_point_cloud(ply_path, pcd)\n",
    "\n",
    "# Print number of points and file path\n",
    "num_points = len(points) if points is not None else 0\n",
    "if ok:\n",
    "    print(f\"Saved point cloud with {num_points} points to: {ply_path}\")\n",
    "else:\n",
    "    print(f\"Failed to write point cloud to: {ply_path}\")\n",
    "\n",
    "# Visualize\n",
    "try:\n",
    "    o3d.visualization.draw_geometries([pcd], mesh_show_back_face=True)\n",
    "except Exception as e:\n",
    "    print(f\"Visualizer error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a58fb9c",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f833711",
   "metadata": {},
   "source": [
    "| Number of Images | Using Segmentation? | Output number of points | Reconstruction Time in CPU | Point Cloud Reconstruction Quality (1-10) |\n",
    "| - | - | - | - | - |\n",
    "| 20 | No | 1,624,353 | 535.09s | 7 |\n",
    "| 10 | No | 812,204 | 122.73s | 8 |\n",
    "| 8 | No | 649,760 | 92.79s | 7 |\n",
    "| 4 | No | 324,876 | 43.04s | 7 |\n",
    "| 3 | No | 243,649 | 33.01s | 6 |\n",
    "| 20 | Yes | 1,412,505 | 457.17s | 3 | \n",
    "| 10 | Yes | 702,301 | 173.50s | 2 |  \n",
    "| 8 | Yes | 562,245 | 130.34s | 2 | \n",
    "| 4 | Yes | 273,803 | 59.2s | 2 | \n",
    "| 3 | Yes | 208,322 | 42.70s | 3 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
