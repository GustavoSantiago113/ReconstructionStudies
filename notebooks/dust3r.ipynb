{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba409c8c",
   "metadata": {},
   "source": [
    "# Dust3r implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d291181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning, cannot find cuda-compiled version of RoPE2D, using a slow pytorch version instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gusta\\Documents\\ProjetosDiversao\\ReconstructionStudies\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\gusta\\Documents\\ProjetosDiversao\\ReconstructionStudies\\notebooks\\../dust3r\\dust3r\\cloud_opt\\base_opt.py:275: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @torch.cuda.amp.autocast(enabled=False)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(\"../dust3r/\")\n",
    "\n",
    "from dust3r.inference import inference\n",
    "from dust3r.model import AsymmetricCroCo3DStereo\n",
    "from dust3r.utils.image import load_images\n",
    "from dust3r.image_pairs import make_pairs\n",
    "from dust3r.cloud_opt import global_aligner, GlobalAlignerMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2afdb0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Loading images from ../images/\n",
      " - adding stop_01_20251128_141444.jpg with resolution 3000x4000 --> 384x512\n",
      " - adding stop_02_20251128_141452.jpg with resolution 3000x4000 --> 384x512\n",
      " - adding stop_03_20251128_141501.jpg with resolution 3000x4000 --> 384x512\n",
      " - adding stop_04_20251128_141510.jpg with resolution 3000x4000 --> 384x512\n",
      " - adding stop_05_20251128_141518.jpg with resolution 3000x4000 --> 384x512\n",
      " - adding stop_06_20251128_141527.jpg with resolution 3000x4000 --> 384x512\n",
      " - adding stop_07_20251128_141536.jpg with resolution 3000x4000 --> 384x512\n",
      " - adding stop_08_20251128_141544.jpg with resolution 3000x4000 --> 384x512\n",
      " - adding stop_09_20251128_141553.jpg with resolution 3000x4000 --> 384x512\n",
      " - adding stop_10_20251128_141602.jpg with resolution 3000x4000 --> 384x512\n",
      " - adding stop_11_20251128_141611.jpg with resolution 3000x4000 --> 384x512\n",
      " - adding stop_12_20251128_141620.jpg with resolution 3000x4000 --> 384x512\n",
      " - adding stop_13_20251128_141628.jpg with resolution 3000x4000 --> 384x512\n",
      " - adding stop_14_20251128_141637.jpg with resolution 3000x4000 --> 384x512\n",
      " - adding stop_15_20251128_141646.jpg with resolution 3000x4000 --> 384x512\n",
      " - adding stop_16_20251128_141655.jpg with resolution 3000x4000 --> 384x512\n",
      " - adding stop_17_20251128_141703.jpg with resolution 3000x4000 --> 384x512\n",
      " - adding stop_18_20251128_141712.jpg with resolution 3000x4000 --> 384x512\n",
      " - adding stop_19_20251128_141721.jpg with resolution 3000x4000 --> 384x512\n",
      " - adding stop_20_20251128_141730.jpg with resolution 3000x4000 --> 384x512\n",
      " (Found 20 images)\n",
      ">> Inference with model on 380 image pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/380 [00:00<?, ?it/s]c:\\Users\\gusta\\Documents\\ProjetosDiversao\\ReconstructionStudies\\notebooks\\../dust3r\\dust3r\\inference.py:44: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=bool(use_amp)):\n",
      "c:\\Users\\gusta\\Documents\\ProjetosDiversao\\ReconstructionStudies\\notebooks\\../dust3r\\dust3r\\model.py:206: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "c:\\Users\\gusta\\Documents\\ProjetosDiversao\\ReconstructionStudies\\notebooks\\../dust3r\\dust3r\\inference.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "100%|██████████| 380/380 [52:58<00:00,  8.37s/it]\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'  # or 'cuda' if you have a GPU\n",
    "batch_size = 1\n",
    "schedule = 'cosine'\n",
    "lr = 0.01 # learning rate for global alignment optimization\n",
    "niter = 300 # number of iterations for global alignment optimization\n",
    "\n",
    "model_name = \"naver/DUSt3R_ViTLarge_BaseDecoder_512_dpt\"\n",
    "\n",
    "# you can put the path to a local checkpoint in model_name if needed\n",
    "model = AsymmetricCroCo3DStereo.from_pretrained(model_name).to(device)\n",
    "\n",
    "# load_images can take a list of images or a directory\n",
    "images = load_images(\"../images/\", size=512)\n",
    "pairs = make_pairs(images, scene_graph='complete', prefilter=None, symmetrize=True)\n",
    "output = inference(pairs, model, device, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20e3c53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " init edge (2*,4*) score=np.float64(21.498865127563477)\n",
      " init edge (2,1*) score=np.float64(19.41025733947754)\n",
      " init edge (16*,1) score=np.float64(19.210765838623047)\n",
      " init edge (3*,1) score=np.float64(17.95309066772461)\n",
      " init edge (1,19*) score=np.float64(16.73318862915039)\n",
      " init edge (4,11*) score=np.float64(16.52924156188965)\n",
      " init edge (5*,3) score=np.float64(16.426549911499023)\n",
      " init edge (8*,11) score=np.float64(16.35724449157715)\n",
      " init edge (3,0*) score=np.float64(15.730518341064453)\n",
      " init edge (1,18*) score=np.float64(15.020994186401367)\n",
      " init edge (1,17*) score=np.float64(14.386512756347656)\n",
      " init edge (3,6*) score=np.float64(13.243693351745605)\n",
      " init edge (11,13*) score=np.float64(12.499796867370605)\n",
      " init edge (14*,11) score=np.float64(12.340362548828125)\n",
      " init edge (15*,11) score=np.float64(20.018617630004883)\n",
      " init edge (5,10*) score=np.float64(17.963863372802734)\n",
      " init edge (8,12*) score=np.float64(16.6411190032959)\n",
      " init edge (12,9*) score=np.float64(16.278690338134766)\n",
      " init edge (7*,10) score=np.float64(13.325974464416504)\n",
      " init loss = 0.015229584649205208\n",
      "Global alignement - optimizing for:\n",
      "['pw_poses', 'im_depthmaps', 'im_poses', 'im_focals']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]c:\\Users\\gusta\\Documents\\ProjetosDiversao\\ReconstructionStudies\\notebooks\\../dust3r\\dust3r\\cloud_opt\\base_opt.py:366: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
      "Consider using tensor.detach() first. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\autograd\\generated\\python_variable_methods.cpp:837.)\n",
      "  return float(loss), lr\n",
      "100%|██████████| 300/300 [31:52<00:00,  6.38s/it, lr=1.27413e-06 loss=0.005374]  \n"
     ]
    }
   ],
   "source": [
    "# next we'll use the global_aligner to align the predictions\n",
    "# depending on your task, you may be fine with the raw output and not need it\n",
    "# with only two input images, you could use GlobalAlignerMode.PairViewer: it would just convert the output\n",
    "# if using GlobalAlignerMode.PairViewer, no need to run compute_global_alignment\n",
    "scene = global_aligner(output, device=device, mode=GlobalAlignerMode.PointCloudOptimizer)\n",
    "loss = scene.compute_global_alignment(init=\"mst\", niter=niter, schedule=schedule, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c45850f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dust3r.viz.SceneViz at 0x1e6393f2480>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieve useful values from scene:\n",
    "imgs = scene.imgs\n",
    "focals = scene.get_focals()\n",
    "poses = scene.get_im_poses()\n",
    "pts3d = scene.get_pts3d()\n",
    "confidence_masks = scene.get_masks()\n",
    "\n",
    "# visualize reconstruction\n",
    "scene.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15cf3974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1927307 points to '../reconstructions/dust3r.ply'\n"
     ]
    }
   ],
   "source": [
    "# Save pts3d (tensor/ndarray/list) to a PLY file with optional masks/colors\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "\n",
    "def _to_numpy(x):\n",
    "    try:\n",
    "        import torch\n",
    "        if isinstance(x, torch.Tensor):\n",
    "            return x.detach().cpu().numpy()\n",
    "    except Exception:\n",
    "        pass\n",
    "    return np.asarray(x)\n",
    "\n",
    "def save_pts3d_ply(pts3d, masks=None, colors=None, filename=\"output_pointcloud.ply\"):\n",
    "    \"\"\"\n",
    "    Save 3D points to a PLY file.\n",
    "    - pts3d can be:\n",
    "        * a single array/tensor of shape (H,W,3) or (N,3)\n",
    "        * a list/tuple of arrays/tensors [(H,W,3), ...] or [(M,3), ...]\n",
    "    - masks (optional) can match pts3d structure: single (H,W) bool array or list of masks\n",
    "    - colors (optional) can be same shape as pts3d (H,W,3) or list; values 0-255 or 0-1 accepted\n",
    "    \"\"\"\n",
    "    is_sequence = isinstance(pts3d, (list, tuple))\n",
    "    pts_list = pts3d if is_sequence else [pts3d]\n",
    "    masks_list = None if masks is None else (masks if isinstance(masks, (list, tuple)) else [masks])\n",
    "    colors_list = None if colors is None else (colors if isinstance(colors, (list, tuple)) else [colors])\n",
    "\n",
    "    collected_pts = []\n",
    "    collected_cols = []\n",
    "\n",
    "    for i, p in enumerate(pts_list):\n",
    "        p_np = _to_numpy(p)\n",
    "        if p_np.size == 0:\n",
    "            continue\n",
    "\n",
    "        if p_np.ndim == 3 and p_np.shape[2] == 3:\n",
    "            if masks_list is not None and i < len(masks_list):\n",
    "                m = _to_numpy(masks_list[i]).astype(bool)\n",
    "            else:\n",
    "                m = np.isfinite(p_np[..., 0])\n",
    "            pts_sel = p_np[m]\n",
    "        elif p_np.ndim == 2 and p_np.shape[1] == 3:\n",
    "            pts_sel = p_np.reshape(-1, 3)\n",
    "            if masks_list is not None and i < len(masks_list):\n",
    "                m = _to_numpy(masks_list[i]).reshape(-1).astype(bool)\n",
    "                pts_sel = pts_sel[m]\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported pts3d shape {p_np.shape}\")\n",
    "\n",
    "        collected_pts.append(pts_sel.reshape(-1, 3))\n",
    "\n",
    "        if colors_list is not None and i < len(colors_list):\n",
    "            c_np = _to_numpy(colors_list[i])\n",
    "            if c_np.ndim == 3 and c_np.shape[2] == 3:\n",
    "                c_sel = c_np[m].reshape(-1, 3)\n",
    "            elif c_np.ndim == 2 and c_np.shape[1] == 3:\n",
    "                c_sel = c_np.reshape(-1, 3)\n",
    "                if masks_list is not None and i < len(masks_list):\n",
    "                    c_sel = c_sel[m]\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported colors shape {c_np.shape}\")\n",
    "            collected_cols.append(c_sel.reshape(-1, 3))\n",
    "\n",
    "    if not collected_pts:\n",
    "        raise RuntimeError(\"No points to save.\")\n",
    "\n",
    "    pts_all = np.concatenate(collected_pts, axis=0)\n",
    "\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(pts_all.astype(np.float64))\n",
    "\n",
    "    if collected_cols:\n",
    "        cols_all = np.concatenate(collected_cols, axis=0).astype(np.float64)\n",
    "        if cols_all.max() > 1.5:\n",
    "            cols_all = cols_all / 255.0\n",
    "        cols_all = np.clip(cols_all, 0.0, 1.0)\n",
    "        pcd.colors = o3d.utility.Vector3dVector(cols_all)\n",
    "\n",
    "    ok = o3d.io.write_point_cloud(filename, pcd)\n",
    "    if not ok:\n",
    "        raise RuntimeError(f\"Failed to write point cloud to {filename}\")\n",
    "    print(f\"Saved {len(pts_all)} points to '{filename}'\")\n",
    "\n",
    "# Example usage:\n",
    "save_pts3d_ply(pts3d, masks=confidence_masks, colors=imgs, filename=\"../reconstructions/dust3r.ply\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a60c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1927307 points from ../reconstructions/dust3r.ply\n",
      "Cleaned -> 1476778 points\n",
      "Cleaned -> 1476778 points\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from utils.pointCloud import clean_point_cloud, visualize_point_cloud\n",
    "\n",
    "# Example: read the PLY we saved earlier, clean it, and visualize\n",
    "ply_path = '../reconstructions/dust3r.ply'\n",
    "try:\n",
    "    pcd = o3d.io.read_point_cloud(ply_path)\n",
    "except Exception:\n",
    "    pcd = None\n",
    "\n",
    "if pcd is None or len(pcd.points) == 0:\n",
    "    print(f'Could not read {ply_path} or file empty — you can call save_pts3d_ply first or pass another path.')\n",
    "else:\n",
    "    print(f'Loaded {len(pcd.points)} points from {ply_path}')\n",
    "    pcd_clean = clean_point_cloud(pcd, method='statistical', nb_neighbors=50, std_ratio=0.5, voxel_size=None)\n",
    "    print(f'Cleaned -> {len(pcd_clean.points)} points')\n",
    "    visualize_point_cloud(pcd_clean, window_name='Dust3R Reconstruction (cleaned)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
